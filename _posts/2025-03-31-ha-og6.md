---
layout: post
title: "The Alternate Hypothesis of OG-6"
date: 2025-03-31
categories: jekyll update
image: /images/posts/mar25/Battle_of_Trenton.jpg
image1: /images/posts/mar25/Washington-wretched-army.jpg
image2: /images/posts/mar25/dist.png
image3: /images/posts/mar25/area.png
image4: /images/posts/mar25/qqplot.png
image5: /images/posts/mar25/hist.png
image6: /images/posts/mar25/t_test.png
---

*Dearest Mother,*

*I am writing you this letter in the hope that I will deliver it to you personally.  My enlistment is up within the fortnight, and I am eager to rejoin you on the farm in time for Spring.  Upon my arrival I will also offer my apologies for not writing since acting on my decision to take up arms against the Red Coats.  I do hope you will forgive my decision, for it was with the best of intentions.  Our financial situation is not lost on me, and the promise of nine months earnings could help us pull through at least one more harvest.  That is, of course, if this Continental currency holds any value by the time I return...*

*I'm honestly unsure I would make the same decision if presented it again.  Since Brooklyn, it seems that all we do is flee further inland.  To think that just a few months ago we held such confidence in our position on Long Island.  And, the last image I have of New York is of it engulfed in fire.  We encamp in one spot for just a few days before the King's men or the Hessians are on the move.  Somehow, though, the Old Fox continues to keep them at bay.  Since winter's onset, both food and ammunition always seem to be in short supply.  Even the locals, those who are sympathtic to our cause, seem to look the other way in our presence.  It is as if they hold less optimism for our success than we do, and yet we are the ones who march through the night often without shoes or coats.  We are the ones who face the gallows if we desert, or impressment into His Majesty's Navy if we are captured.  The soldiers' lot is bleak, my dearest Mother.*

*Tomorrow is Christmas Eve and we are preparing something bold, I am told.  The Old Fox has us making preparations to cross the Deleware for a place called Trenton.  I am told the Hessians have set up for the winter there, and my guess is this is our Fox's last chance before all our enlistments are through.  It does little to lighten the heart to know that our sentry's password and challenge tonight is "Victory or Death."  I know not why I write this to you, Mother, except perhaps it is the cold, hunger and fear that have crept into my bones.  It is my hope that this letter will never come to you, and that in three months time we will be reunited.  Pray for us all, Mother*

*Signed: Your Loving Son, 24 December, 1776*

![March]({{page.image1 | relative_url}})

### Hypothesis Testing the Battle of Trenton

Two guesses who the *'Old Fox'* was...  That's right, the Original Gangster :>  In the spirit of contemporary military parlance, let's just refer to him as OG-6.  Although the year began with a confident Continental Army arriving in New York after a sucessful go at the British at Bunker Hill, by year end the mood had decidedly shifted.  Outnumbered and outmaneuvered at the Battle of Brooklyn in the Summer of 1776, OG-6 retreated from New York only by luck of foul weather that concealed his movements.  His steady retreat spanned the Fall and crept into December, taking the army from a demolished New York City north to present day Westchester County, across the Hudson into New Jersey, past Newark, and ultimately across the Deleware from Trenton.  Suffice it to say that the army was on its last legs.  The Continental Congress had fled Philadelphia, *'American'* currency was nearly worthless, supplies were thin, roughly half of the colonial population sided with the British, and a significant number of enlistments were due to expire in January.  Without a turn in morale, OG-6 would be unable to enlist more volunteers.  The odds were good that he, along with a few other American traitors, would soon meet the long end of a rope.  And, that would have been the end of the American Project.  So, this was the situation in which OG-6 found himself. He needed a victory, or it would be death.

I raise this story because, in my view, it is a good example of decision making through hypothesis testing.  Yes, it's also a demonstration of decision making under pressure, and I'm sure OG-6 didn't formally *"state his alternate hypothesis"* or *"reject his null hypothesis,"* but follow me on this one for a moment while I don my nerd spectacles...

Hypothesis testing is a core statistical concept.  It is the structural framework through which decisions are made based on a rigorous analysis of the data available.  Given the task of making a decision in an uncertain world armed only with some factual prior observations and a handful of assumptions, structuring the decision problem as a hypothesis test allows one to make an *informed* decision within a specified confidence level.  *Informed* is the key word, since the outcome is never certain.  Inaccurate data, flawed assumptions, and pure bad luck can all lead to the wrong decision.  That is why in the realm of probability and statistics, one can never be 100% certain.  The strongest assertion we can ever make is that something is true, *almost surely.*  It can be infuriating to content with that specter of uncertainty, but that's just how probabilies work.  So, next time someone asks you if you are positively sure that imposing 20th-Century-style tariffs on your trading partners is a bad idea, try responding with "Yes! Almost surely!!"  You're almost surely to get strange looks.  Jokes aside, leaders are charged with making decisions, and having a process beats sticking a finger in the air most of the time, almost surely.

How does the process work, then?  There are countless resources out there that describe the hypothesis testing framework in similar ways.  My personal favorite approach is the six-step proess outlined in the CFA curriculum:
1. **State the hypothesis.**  In stating the hypothesis, you're actually making two statements.  The first is the null hypothesis $$(H_o)$$, or the statment that contradicts what you suspect to be true.  The second is the alternate hypothesis $$(H_a)$$, in which you state what you suspect to be true.  In OG-6's case, it might have been:


    $$H_o:$$ A surprise attack on Trenton will fail because the Hessians are prepared and the American army is too weak.

    $$H_a:$$ The Hessians will be vulnerable due to post-Christmas fatigue, and a well-executed surprise attack can result in victory.

2. **Identify the appropriate test statistic.**  Typically, one would leverage a statistical measure based on the assumed probability distribution that characterizes the data.  In our historical case study, it likely analogizes best to think of this step as determining the key factors that should inform the decision, such as:
    - The likelihood that the Hessians would expect the Americans to abide by the conventional norm of ceasing military activities during winter.  As such, they would likely celebrate Christmas and be vulnerable to a surprise attack.
    - A belief that, since the British had spread its forces thin in the area in preparation for winter, the town would be lightly defended and difficult to reinforce.
    - A realization that American morale was nearing a breaking point, and opportunities to turn it around were scarce.

3. **Specify the level of significance.**  Getting back to that *uncertainty* thing..  Specifying a significance level for your hypothesis test is equivalent to establishing how much confidence you want to have in your decision.  The relationship between significance level, $$\alpha$$, and confidence, $$C$$, is $$\alpha = 100 - C$$.  Your gut reaction might be to say that you want to be 100% confident in your decision, e.g., a level of significance of 0 $$(100\% - 100\%)$$.  The trouble there, which we'll discuss further below, is that an unreasonably high[low] level of confidence[$$\alpha$$] puts you at risk of decision paralysis.  A typical level of significance is $$\alpha = 0.05$$, which suggests that you will be 95% confident in your decision.

4. **State the decision rule.**  This step uses the output of (2) and (3) to formalize our *go/no-go* decision.  When working with quantifiable data, we will compare our test statistic from (2) against the *critical value (CV)* that aligns with our stated significance level from (3) - more on that in our worked case study.  If the test statistic is below the CV, then we will conclude there is not enough evidence to reject the null hypothesis.  In that case OG-6 would call off the surprise attack because he would be reasonably confident it would fail.  On the other hand, if the test statistic is above the CV, we will reject the null and accept the alternate hypothesis, i.e., proceed with the attack because we're reasonably confident of success.  I envision OG-6, rather than looking up probability tables and running calculations, was instead reasoning in his mind the odds that his base assumptions underlying the Trenton plan held true.

5. **Calculate the test statistic.**  In practice, this step entails data collection and processing to arrive at a measure to compare against the CV from (4).  OG-6, for his part, would have leveraged his extensive network of spies and informants, his knowledge of British standard operating procedure, and a wealth of knowledge accumulated in the course of out-foxing the Red Coats.  On compiling all the relevant data, he would have built a set of facts to weigh against the critical factors informing his go/no-go decision.

6. **Make a decision.**  Time to lead, you leader!  In this final step, you are armed with data, you have a test measure from (5) and a CV from (4).  You implement your decision rule and make that decision.  This is not to say that at this point you let the chips fall where they may and blindly execute on the decision.  As new information becomes available, it is important to reassess the decision and determine if revisions are necessary.  For instance, OG-6 may have found that crossing the Deleware became impossible as a northeaster set in that night.  Or, a sufficient number of his supporting forces may not have been able to reach their objectives and aborted their part in the operation (which actually happened).  

The hypothesis testing framework is rigorous, but not rigid.  Even if OG-6 would not have recognized his decision process in the way I've described it here, his objective and flexible application of hypothesis testing enabled him to execute a daring surprise attack that neutralized the Hessian presence in Trenton.  The battle is widely seen as the turning point in the Revolution, after which the British never regained their momentum.

### Equity Market Risk Premium

That's right, there's only so much one can write about Trenton, NJ.  Let's turn our sights to another practical application of hypothesis testing.  Have you, as an investor, ever asked yourself if you are being sufficiently rewarded for investing in the equity market?  If not, then, let's do it now.  In a world flush with options for how to deploy capital, let us ask the simple question: "Should I invest my capital in equities, i.e., stocks, or should I put it towards government bonds?" In the former, I'm betting on the hope that my capital appreciates and I earn a return on my investment.  On the latter, I'm resigned to the fact that my investment will at best keep pace with the *risk-free* interest rate of growth.  I'm assuming market risk with the former, and there's a good chance that I will lose money.  In the latter, I'm banking on the idea that the U.S. will not default and my principal is secure - historically a very good assumption.  By this logic, I should base my decision to allocate capital to equities if I can expect to earn an average rate of return $$(r_e)$$ in excess of the risk-free rate $$(r_f)$$. This excess return is the **equity market risk premium**, or **ERP**, defined as:

$$
ERP = r_e - r_f  \tag{1}
$$

As with many things in finance, there are several ways to measure ERP.  For instance, one can take a forward-looking view, or *ex ante*, by measuring ERP as a function of market P/E ratios, expected dividend rates and GDP growth outlooks.  If you have confidence in your forecasting abilities, then this is a good measure that incorporates your expectations for the future.  Another way to measure to ERP is backwards-looking, or *ex post*.  Rather than making explicit predictions, this approach assumes that history is a good guide to the future.  Clearly, there are shortcomings to both approaches.  Your ex ante inputs could be fundamentally flawed, resulting in inaccurate forward-looking estimates.  On the other hand, past performance does not guarantee future results, and ex post estimates that characterized a prior regime may no longer hold if the regime has changed.  One need not look further than the first quarter of 2025 in America to illustrate the challenge.  2024 ended on a bullish note following a strong bull run.  2025 woke up on the wrong side of bed.  If you grounded your ERP viewnon ex ante assumptions, then your model is already invalidated.  Similarly, if you assumed the 2024 music would keep playing, then your ex post estimates are potentially biased from the prior regime.  Confronted with this challenge, my personal view, from the standpoint of a long-term investor, is to favor an ex post approach with a sufficiently long time horizon that captures potentially more than one regime.  

So, on that note, here's our task, conditions and standard this month:

**Task:** Conduct a hypothesis test to determine if ERP is greater than 0 over the long run.

**Conditions:** Data inputs will consist of the **SPY** etf as a proxy for the U.S. equity market and **3-Month (T-Bill) Treasury** yields as a proxy for the risk-free rate.  We'll use price action and yields dating back to the early 1990's.

**Standard:** Apply the 6-step framework to structure a rigorous hypothesis test to inform our decision.

Taking a break from Python, this month we'll conduct the exercise in R.  For those not familiar with R, it comes just before S :>  I'll be here all week, folks...  Actually, R is a statistical software that was named somewhat in jest as an open source version of S and S-Plus.  While I'll be the first to admit that gaining proficiency in R is a bit of a dark art, it is an extremely powerful tool for statistical analysis, and a very good addition to Python in the quantitative analyst's kit.  For those who like to dig into the code, you can find this analysis in the [companion notebook](https://github.com/rtrimble13/tb-notebooks.git).

### By the Numbers...

And here we go, starting at the top:

## Step 1

We want to test our hypothesis that long-term ERP is greater than 0.  Our null and alternate hypotheses are thus:

$$
H_o := ERP \le 0 \\
H_a := ERP \gt 0
$$
 
If we simply wanted to test that ERP was non-zero, then we could have stated:

$$
H_o := ERP = 0 \\
H_a := ERP \neq 0
$$

This small nuance would have downstream implications.  However, we'll stick with the first statement since we want to base our investment decision on the premise that ERP is positive.

## Step 2

We're not tackling Trenton here; we need a more quantifiable measure to test.  In our case, we'll make the assumption that our estimate of long-term average ERP, or $$\mu{ERP}$$, is **Student's-T distributed** with 375 degrees of freedom.  "Say what??" you ask..  I'll explain.  We have to make an assumption that average ERP conforms to some probability distribution.  We could assume it is normally distributed, like the classical bell curve that describes many things in the world, such as the IQ's of the world's population, or the height of people with brown hair (I'm being random on purpose..).  Often times, though, assuming normality is too strong of an assumption due to the presence of outliers, especially when the dataset is not sufficiently large.  The Student's-T distribution is commonly used in statistics.  It resembles the normal bell curve, but has "fatter tails" at lower degrees of freedom.  Whereas the normal distribution must be specified with a mean $$(\mu)$$ and standard deviation $$(\sigma)$$, Student's-T has one parameter, degrees of freedom.  We set that parameter as one less than the number of observations in our dataset, or 375 for monthly data between 1993 and Feb'25.  The below plot compares the normal verses T at with different degrees of freedom.  We can see that the T converges to normal as degrees of freedom increases.  Intuitively this makes sense because data becomes more "normal" as the number of observations grows.

![Distribution Plot]({{page.image2 | relative_url}})

In settling on our choice of distribution (Student's-T), we'll define our test statistic as:

$$
t = \frac{\bar{\mu_{ERP}} - 0}{\frac{\sigma_{\bar{\mu_{ERP}}}}{\sqrt{n}}}
$$

where $$\bar{\mu_{ERP}}$$ is average ERP, and the denominator is our measure of standard error as a function of the standard deviation of ERP and the number of observations in our dataset.  Said differently, the test statistic is our measure of how different our average ERP is from 0, normalized by the variation of ERP in our observation set.

## Step 3

In keeping with convention, we'll specify a significance $$\alpha$$ of 0.05, which corresponds to a 95% $$(= 100 - 0.05)$$ level of confidence.  To better understand this concept, it helps to visualize the probability density curve, .i.e, the bell curve.  

![Area under the curve]({{page.image3 | relative_url}})

Focusing on the left-hand plot, our test statistic, t-stat for short, will fall somewhere along the x-axis.  If it happens to be ~-2.2, for instance, then that would mean approximately 2.5% of the area under the curve is to the left of the t-stat (the shaded region in the left tail).  In this case, assuming we were conducting a two-sided test in line with the second set of hypothesis statements above, we would conclude that average ERP is significantly different (less than) 0, which would cause us to reject the null hypothesis and accept the alternate.  If instead the t-stat was 0 - in the middle of the distribution - then that would mean it is in the 50% percentile, or half of the area under the curve is less than the t-stat.  In that case, we would conclude there is not sufficient evidence that average ERP is different from 0 and we would fail to reject the null hypothesis.  This would be equivalent to OG-6 deciding against his surprise attack.  Since we are conducting a one-sided test, we should focus on the right-hand plot.  The shaded area to the right denotes the 5% $$\alpha$$ significance, or the 5% of the area under the curve that will help us decide if our t-stat is significantly greater than 0.  The shaded areas in both plots represent our 95% confidence threshold for rejecting the null hypothesis.  With fewer observations (data points), the tails of the curves would be larger, and the areas that represent 5% of the distribution would be further away from 0.  Intuitively, this is because the standard errors of our measurements would be higher, thus requiring a larger t-stat for us to reject the null.

## Step 4

We're getting there...  Given our choice of $$\alpha = 0.05$$ and T-distribution with 375 degrees of freedom, we can identify the critical value that corresponds to the shaded area in the right-hand plot above.  R makes this very simple:

```R
## Determining the t-test critical value..
n <- length(erp) - 1   # erp is our dataset of monthly excess returns of SPY over T-bill yields since 1993; n is our degrees of freedom.

alpha <- 0.05          # significance level
crit_value <- qt(p = alpha, df = n, lower.tail = FALSE)
```
The *qt* funtion returns the value representing the qth percentile in the T-distribution.  For us, this value is +1.65.  If our yet-to-be-computed t-stat is greater than 1.65, then we know it falls within the top (right-hand side) 5% in the distribution of probable values.  We would then conclude that our t-stat and our average ERP is significantly greater than 0.  Otherwise, we'll have to conclude insufficient evidence to make that claim.

## Step 5

Now we can start working with out data.  Starting with **SPY**, we need to transform daily adjusted-close prices into monthly returns:

```R
spy_monthly <- spy_daily[, .(adjClose = last(adjClose)),
                         by = .(year(date), month(date))]

## reformat the date and compute returns
spy_monthly[, date := as.Date(paste(year, month, "01", sep = "-"))]
spy_monthly <- spy_monthly[, .(date, adjClose)]
spy_monthly[, rtn := round((adjClose / shift(adjClose) - 1) * 100, 2)]
```

Next, we need to convert our 3-Month T-Bill yields into monthly equivalent yields.  Since the yield on a T-Bill is quoted in simple annual rates - simple because they do not pay coupons - we will simply divide by 12 to get the monthly equivalent:

```R
t_bill <- t_bill[, .(date, rate)]  # t_bill already pre-processed to monthly observations similar to SPY

t_bill[, rate := round(rate / 12, 2)]
```

Finally, we merge the two series into one dataset and compute ERP for each month:

```R
erp_monthly <- na.omit(merge(spy_monthly, t_bill, by = "date", all.x = TRUE))

erp_monthly[, erp := rtn - rate]
```

Before going further, let's take a few moments to note a few key assumptions we have to make for our test to be valid:
1. Our random variable, monthly ERP in this case, should be independent and identically distributed, or i.i.d.  Based on our sampling approach, i.e., using monthly returns and yields, we satisfy this assumption.
2. Our data should be approximately normally distributed.  We can plot a histogram and Quantile-Quantile chart to check this assumption.
3. Our data should be continuous, meaning that ERP can theoretically take on any value between +/- infinity, which it can.

The below plots show the monthly time series of ERP and associated QQ chart.  The the left-hand chart we see ERP is both positive and negative through time.  By visual inspection, it's plausible that it is positive on average, though not surprising to see the negative values tend to have larger magnitudes than the positive ones.  The right-hand chart compares the empirical quantiles relative to theoretical, normally distributed ones.  If our data was truely normally distributed, then all of the points would fall neatly on the red line.  The tails of our data veer off the line, though, so we know we're not dealing with a truely normal set.  For our purposes, though, we can say the data is normal enough to support our assumptions.

![QQ]({{page.image4 | relative_url}})

Here we plot a histogram of ERP and compare with a normal distribution.  As we saw in the time series plot, there is a negative skew driven by the larger values in the left tail.  The sample average is 73 basis points.  So long as the standard error does not dominate the t-stat, we will be able to conclude that this estimate is significantly greater than 0.

![ERP Histogram]({{page.image5 | relative_url}})

If you're still with me, I applaud your moxy.  We'll calculate our test statistic with one more line of code:

```R
t.test(erp_monthly$erp, mu = 0, alternative = "greater")
```

In the above, we're computing our t-stat as defined in equation (1), specifying that the value we're comparing average ERP against is 0, and that the test is one-sided, e.g., "greater" than 0.

## Step 6

Time to evaluate the test results and make a decision!

![T-Test]({{page.image6 | relative_url}})

The test output contains all the information we need to make a decision.  Let's interpret it line by line:
1. Our data is monthly observations of ERP.
2. The computed t-stat is 3.11 (recall the critical value is 1.65), based on 375 degrees of freedom.  
3. The p-value is close to 0, and well below our significance level of 0.05.  This means the probability of average ERP being less than or equal to 0 to be virtually 0.
4. The 95% confidence interval of average ERP to be significant is $$[0.37, +\infty)$$, and our estimated mean value of 73bps is within that interval.

So, based on this test result, we will reject the null hypothesis and conclude that there is positive premium over the risk-free rate to be earned by investing in equities.  Great success!!  Annualizing 73bp suggests an 8.76% annual ERP on average.  

To the seasoned investor, the result is probably obvious, almost surely.  However, what we've demonstrated is a rigorous approach to decision making that can be generalized towards all sorts of problems, and, in my view, is something to celebrate.  This sprawling narrative barely scratches the surface (of the theory, application, and flexibility of this framework), but I hope it has provided some insight to the power of applied statistics in making informed decisions.

### A PSA on Error

As discussed earlier, there is no certainty in decision making.  Even when acting on flawless information built from the strongest assumptions, there remains uncertainty in the outcome.  So, it is useful to talk a little of the types of errors we may encounter as a result of our decisioning.  

When we reject $$H_o$$ even though it is correct, we are making a **Type I** error.  This is an error of commission, meaning that we are accepting the alternate hypothesis when it is in fact a false positive.  These sorts of errors are often the easiest to measure because we've taken an action only to learn first hand that it was the wrong decision.  If we set our significance level too high, it increases the chances of a Type I.  This is because the t-stat has a higher likelihood of being greater than the critical value, making us more likely to reject the null.  

- For OG-6, a Type I error would have resulted in encountering a well-fortified and angry mob of Hessians just waiting to mow down the Continentals.
- In our case, a Type I error would be acting on the decision to invest in equities only to find that T-Bill's outpace our returns over the foreseeable future.

Another type of error occurs when we fail to reject $$H_o$$ even though it is wrong.  This is an error of omission, commonly thought of as an opportunity cost.  In this case we reject the alternate hypothesis when it is actually true.  We fail to act when we should have done so.  This is a **Type II** error, also known as a False Negative.  It can happen if we set our significance level too low, increasing the chances that the t-stat will have less magnitude than the critical value.  These errors are just as bad as Type Is, but they are also more difficult to measure and less often felt directly.  

- For OG-6, a Type II would have resulted from a decision to call off the attack.  As a missed opportunity, the demoralized Colonial Army would have fallen appart, and today we Americans would be drinking tea (true, there are worse things..).
- In our case, a Type II error would have us sink our wealth in Treasuries and miss out on the opportunity to earn more in equities.

So, there you have it.  I, for one, believe that OG-6, like Chuck Norris, always correctly rejected the null hypothesis, almost surely :>

Action front!  Let's move out and draw fire!!

**Note:** This post is not investment advice.  Any opinions stated are my own, and do not reflect those of my employer.  This post is meant to be educational and entertaining.  If you find it useful, please let me know.  If you think it sucks, and are sure you're not committing a Type I error, please also let me know.  

#### Sources

[Wikipedia: Battle of Trenton](https://en.wikipedia.org/wiki/Battle_of_Trenton)

[American History Central](https://www.americanhistorycentral.com/entries/battle-of-trenton/)

[R Statistical Software](https://cran.r-project.org)

[Federal Reserve Data - FRED](https://fred.stlouisfed.org/)

[TurningBull companion Jupyter Notebook Git Repo](https://github.com/rtrimble13/tb-notebooks.git)

[Financial Modeling Prep (FMP)](https://site.financialmodelingprep.com)